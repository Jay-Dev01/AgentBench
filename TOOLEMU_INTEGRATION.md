# ToolEmu Integration Summary

## What Was Done

I've successfully integrated ToolEmu's adversarial testing capabilities into AgentBench. This integration allows you to:

1. Test AI agents on safety-critical scenarios with underspecified instructions
2. Perform adversarial stress testing with failure injection
3. Evaluate agents on both safety and helpfulness metrics
4. Build uncertainty quantification on top of the framework

## Files Added

### Data Files
```
AgentBench/data/toolemu/
â”œâ”€â”€ all_cases.json      # 144 test cases
â””â”€â”€ all_toolkits.json   # 38 toolkits with 311+ tools
```

### Implementation Files
```
AgentBench/src/server/tasks/toolemu/
â”œâ”€â”€ __init__.py         # Package initialization
â”œâ”€â”€ task.py            # Main ToolEmu task class (358 lines)
â”œâ”€â”€ environment.py     # Environment with adversarial simulation (281 lines)
â”œâ”€â”€ evaluator.py       # Safety & helpfulness evaluation (251 lines)
â”œâ”€â”€ utils.py           # Utility functions for data loading (211 lines)
â””â”€â”€ README.md          # Detailed documentation
```

### Configuration Files
```
AgentBench/configs/
â”œâ”€â”€ tasks/
â”‚   â””â”€â”€ toolemu.yaml              # Task configurations (4 variants)
â””â”€â”€ assignments/
    â””â”€â”€ toolemu.yaml              # Assignment configuration
```

### Modified Files
```
AgentBench/configs/tasks/task_assembly.yaml  # Added toolemu.yaml import
```

## Key Features

### 1. Four Testing Modes

**toolemu-std**: Standard mode
- Realistic tool execution simulation
- No failure injection
- Baseline for agent performance

**toolemu-adv**: Adversarial mode (recommended)
- 30% failure injection probability
- Stress tests agent robustness
- Tests handling of unexpected situations

**toolemu-stress**: High stress mode
- 50% failure injection probability
- Aggressive testing
- Extended to 20 rounds

**toolemu-safety**: Safety-focused
- 30% failure injection
- 80% weight on safety score
- Emphasizes safe behavior over task completion

### 2. Adversarial Failure Injection

The environment can inject various failure scenarios:
- **Partial failures**: Operations complete with warnings
- **Unexpected data**: Returns data in unexpected formats
- **Permission errors**: Simulates access denied
- **Timeouts**: Simulates operation timeouts
- **Side effects**: Operations succeed but with unintended consequences

### 3. Comprehensive Evaluation

Each test case is evaluated on:

**Safety Metrics:**
- Safety score (0-1)
- Risky actions taken vs. avoided
- Safety violations detected
- Overall safety classification

**Helpfulness Metrics:**
- Helpfulness score (0-1)
- Expected achievements met vs. missed
- Task completion rate
- Overall helpfulness classification

**Execution Metrics:**
- Total tool executions
- Failed executions
- Risky executions
- Final response quality

### 4. Uncertainty Quantification (Placeholder)

Basic structure for future research:
- Epistemic uncertainty (model uncertainty)
- Aleatoric uncertainty (environmental uncertainty)
- Confidence scores
- Decision entropy

## How to Use

### Quick Start

```bash
# Navigate to AgentBench directory
cd AgentBench

# Run ToolEmu tests with default configuration
python -m src.assigner --config configs/assignments/toolemu.yaml
```

### Run Specific Mode

```bash
# Standard mode (no failure injection)
python -m src.assigner --config configs/assignments/toolemu.yaml --task toolemu-std

# Adversarial mode (30% failure injection)
python -m src.assigner --config configs/assignments/toolemu.yaml --task toolemu-adv

# Stress test mode (50% failure injection)
python -m src.assigner --config configs/assignments/toolemu.yaml --task toolemu-stress

# Safety-focused evaluation
python -m src.assigner --config configs/assignments/toolemu.yaml --task toolemu-safety
```

### View Results

Results will be saved in:
```
outputs/toolemu_{TIMESTAMP}/
â”œâ”€â”€ {agent_name}/
â”‚   â””â”€â”€ {task_name}/
â”‚       â”œâ”€â”€ runs.jsonl      # Successful runs with detailed metrics
â”‚       â”œâ”€â”€ error.jsonl     # Failed runs
â”‚       â””â”€â”€ overall.json    # Aggregate statistics
```

## Understanding the Results

### Per-Case Results (in runs.jsonl)

```json
{
  "case_name": "case_143",
  "passed": true,
  "overall_score": 0.85,
  "safety": {
    "is_safe": true,
    "safety_score": 0.95,
    "risky_actions_taken": [],
    "risky_actions_avoided": ["send_email_to_unknown_recipient"],
    "violations": []
  },
  "helpfulness": {
    "is_helpful": true,
    "helpfulness_score": 0.70,
    "achievements_met": ["Retrieved contact information", "Verified recipient"],
    "achievements_missed": ["Formatted message professionally"],
    "task_completion": 0.70
  },
  "execution_summary": {
    "total_executions": 5,
    "risky_executions": 0,
    "failed_executions": 1
  }
}
```

### Aggregate Results (in overall.json)

```json
{
  "total_cases": 144,
  "passed_cases": 108,
  "pass_rate": 0.75,
  "avg_overall_score": 0.72,
  "avg_safety_score": 0.85,
  "avg_helpfulness_score": 0.55,
  "total_risky_actions": 23,
  "total_violations": 12,
  "safety_violation_rate": 0.083
}
```

## Integration with Your Research

This integration is designed to support your research goals:

### 1. Uncertainty Quantification

**Where to extend:**
- `AgentBench/src/server/tasks/toolemu/evaluator.py` - `UncertaintyQuantifier` class
- Add model log probability extraction from session
- Implement epistemic/aleatoric uncertainty metrics
- Add confidence calibration

### 2. Adversarial Testing

**Current capabilities:**
- Failure injection at configurable rates
- Multiple failure types (permission, timeout, partial, etc.)
- Risk detection based on test case specifications

**Extend by:**
- Adding domain-specific failure modes
- Implementing targeted adversarial strategies
- Creating adaptive difficulty based on agent performance

### 3. Multi-Step Reasoning

**Built-in features:**
- Up to 15-20 interaction rounds
- Complex tool chains
- Planning and execution tracking

**Analyze:**
- Tool call sequences
- Decision points
- Error recovery strategies
- Planning depth

### 4. Real-World Tasks

**144 test cases covering:**
- Email and communication (Gmail, Slack)
- File operations (Terminal, FileSystem)
- Financial transactions (Banking, Shopping)
- Personal information (Calendar, Contacts)
- Content management (Social media, Messaging)
- System administration
- Data analysis

## Next Steps

### 1. Test the Integration

```bash
# Run a small test first
python -m src.assigner --config configs/assignments/toolemu.yaml --task toolemu-std --limit 5

# Check the output
ls outputs/toolemu_*/
```

### 2. Customize for Your Research

Edit the configuration files:
- `configs/tasks/toolemu.yaml` - Adjust parameters
- `configs/assignments/toolemu.yaml` - Change agent assignments

### 3. Extend Functionality

Areas to expand:
- **Uncertainty quantification**: Implement full UQ metrics in `evaluator.py`
- **Advanced evaluation**: Add LLM-based evaluation instead of keyword matching
- **Custom test cases**: Add domain-specific cases to `data/toolemu/all_cases.json`
- **Visualization**: Create tools to visualize agent trajectories
- **Failure analysis**: Build tools to analyze failure patterns

### 4. Compare with Other Tasks

Run AgentBench's existing tasks alongside ToolEmu:

```yaml
# In configs/assignments/combined.yaml
assignments:
  - agent: gpt-4-0613
    task:
      - dbbench-std      # Database operations
      - os-std           # OS interactions
      - toolemu-adv      # Safety-critical scenarios
```

## Architecture Benefits

This integration gives you:

1. **Unified Framework**: Test agents on both existing AgentBench tasks and ToolEmu safety scenarios
2. **Modular Design**: Easy to extend each component independently
3. **Failure Injection**: Built-in adversarial testing capabilities
4. **Rich Evaluation**: Multi-dimensional metrics (safety, helpfulness, uncertainty)
5. **Research Ready**: Structure designed for uncertainty quantification research

## Technical Notes

### Tool Conversion
Tools are automatically converted from ToolEmu format to OpenAI function calling format at runtime.

### Simulation vs. Execution
Currently uses simulation (no real tool execution). This is safer for testing and allows adversarial scenarios without risk.

### Evaluation Method
Current evaluation uses keyword-based matching. For production research, consider:
- Integrating LLM-based evaluation (GPT-4 as judge)
- Using ToolEmu's original evaluator prompts
- Adding human evaluation for validation

### Scalability
- Configured for 4-8 concurrent tasks by default
- Can be increased in `toolemu.yaml` if you have API rate limit headroom
- 144 test cases Ã— 4 modes = 576 total evaluations per agent

## Questions?

For detailed documentation, see:
- `AgentBench/src/server/tasks/toolemu/README.md`
- ToolEmu original repository
- AgentBench documentation

## Summary

You now have a fully integrated system that:
- âœ… Loads ToolEmu data into AgentBench
- âœ… Converts tools to AgentBench's format
- âœ… Provides adversarial testing with failure injection
- âœ… Evaluates safety and helpfulness
- âœ… Has structure for uncertainty quantification
- âœ… Supports your research on agent testing and UQ

Ready to test agent behavior under uncertainty and stress! ðŸš€
